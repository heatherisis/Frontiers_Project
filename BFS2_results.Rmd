---
title: "Frontiers paper"
author: "Tara McAllister Byun and Heather Campbell"
date: "June 6, 2016"
geometry: margin=2.54cm
output: word_document
header-includes:
- \usepackage[utf8]{inputenc}
- \usepackage[T1]{fontenc}
- \usepackage{lmodern}
- \usepackage{tipa}
- \setlength\parindent{24pt}
- \setlength{\parskip}{0pt}
- \usepackage{setspace}
- \usepackage{httpuv}
- \doublespacing

---
```{r, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}
########################################
#LOAD PACKAGES
########################################
rm(list=ls())
library(plotrix)
library(plyr)
library(fields)
library(reshape2)
library(lme4)
library(ggplot2)
library(plyr)
library(dplyr)
library(car)
library(gridExtra)
library(ppcor)
library(SCRT)
library(httpuv)  
library(caTools)
library(magrittr)
library(tidyr)
```

```{r, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}
################################################################
#THIS CODE LOADS AND CLEANS DATA 
#################################################################

data  = read.csv("BFS2_trials_summarized", sep="\t", header=T)
#str(data)
#data$X.1 <- NULL
#dim(data)
#which(is.na(data$mean))

#Subject as factor
data$subject <- as.factor(data$subject)

#Create a session column
data$sessioncode <- data$Filename
data$study <- as.factor(sapply(strsplit(as.character(data$sessioncode), "\\_"), function(x) x[[1]]))
data$session <- as.factor(sapply(strsplit(as.character(data$sessioncode), "\\_"), function(x) x[[3]]))
#levels(data$session)

#Cleanup: There is inconsistency in whether Tx is written Tx or TX
#fixme <- data[which(grepl("TX", data$session)==T),]
data$session <- recode(data$session, c("'Tx3'='TX3'"))
data$session <- recode(data$session, c("'tx11'='TX11'"))
data$session <- recode(data$session, c("'tx12'='TX12'"))
data$session <- recode(data$session, c("'Tx13'='TX13'"))
data$session <- recode(data$session, c("'Tx17'='TX17'"))
data$session <- recode(data$session, c("'Tx18'='TX18'"))
data$session <- recode(data$session, c("'Tx19'='TX19'"))
data$session <- recode(data$session, c("'Tx20'='TX20'"))
#levels(data$session)

#Create a session type column 
data$sessiontype <- as.factor(substring(data$session,1,2))  
#levels(data$sessiontype)

#Create condition and prepost columns
#Previously these were all starting out as NA; info was filled in to the condition and prepost
#columns for treatment sessions only (not probe sessions). However, the NAs were causing problems,
#so now the default coding is "PROBE."
data$condition <- "PROBE"
data$prepost <- "PROBE"

#Fill in condition and pre/post columns for TREATMENT DATA only
dataBL <- droplevels(data[which(data$sessiontype=="BL"),])
dataMN <- droplevels(data[which(data$sessiontype=="MN"),])
dataMP <- droplevels(data[which(data$sessiontype=="MP"),])
dataTX <- droplevels(data[which(data$sessiontype=="TX"),])

dataTX$prepost <- sapply(strsplit(as.character(dataTX$sessioncode), "\\_"), function(x) x[[4]])
dataTX$condition <- as.factor(sapply(strsplit(as.character(dataTX$sessioncode), "\\_"), function(x) x[[5]]))

#Use tables to check if cleanup is needed
#table(dataTX$prepost)
#table(dataTX$condition)

#Argh, some of the TX sessions have "Probe" or "pre/post" where they ought to have BF/TRAD
#set aside data that don't need changing
gooddata <- filter(dataTX, condition=="BF"|condition=="Trad")
#dim(gooddata)
#Pull out the data to change
checkme <- filter(dataTX, condition!="BF"&condition!="Trad")
#dim(checkme)
#Pull out the subset with "pre" or "post" instead of Trad/BF
prepost <- filter(checkme, condition=="post"|condition=="pre")
#All of the pre/post errors are from one session, so it's easy to fix:
prepost$prepost <- prepost$condition
prepost$condition <- "Trad"
#Pull out the subset with "Probe"
probe <- filter(checkme, condition=="Probe")
#These are also all from one session. According to the calendar, this was a BF session.
probe$condition <- "BF"
#The remaining subset has no _ between BF and word
nounderscore <- checkme[which(grepl("BF", checkme$condition)==T),]
nounderscore$condition <- as.factor(substring(nounderscore$condition,1,2))  
dataTX <- droplevels(rbind(gooddata, prepost, probe, nounderscore))
#table(dataTX$condition)

#Now fix the prepost column
#table(dataTX$prepost)
#Need to standardize capitalization
dataTX$prepost <- recode(dataTX$prepost, c("'post'='Post'"))
dataTX$prepost <- recode(dataTX$prepost, c("'pre'='Pre'"))

#Rebind all
data <- rbind(dataBL, dataMP, dataMN, dataTX)
data$session <- as.factor(data$session)
data$condition <- as.factor(data$condition)
data$prepost <- as.factor(data$prepost)
#levels(data$condition)
#levels(data$prepost)

#Add demographic info
demog = read.csv("BFS2_demog.csv")
demog$subject <- as.factor(demog$subject)
data <- left_join(data, demog, by="subject")
data$subject <- as.factor(data$subject)
#str(data)

#Make session an ordered factor
#levels(data$session)
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5","TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                                "MP1","MP2","MP3","TX11","TX12",
                                                "TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   

#Uncomment this if you want to generate the summarized data file anew
#write.csv(data, "clean_data.csv")
```

##Individual results: Effect sizes

```{r, echo=FALSE, fig.width=7, fig.height=2,message=FALSE, warning=FALSE}
#################################################################
#THIS CODE CALCULATES EFFECT SIZES
#################################################################
data <- read.csv("clean_data.csv")
#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)
#Need to re-set ordered factors
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5","TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                                "MP1","MP2","MP3","TX11","TX12",
                                                "TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   


#This code creates an option to examine only the primary probe words 
#and exclude less frequently occurring generalization items
#Note how these categories are defined: primary means probed in BLMN and PREPOST,
#"generalization" means probed in BLMN only. 
#All are untreated (i.e. not words used as targets during treatment)
#Determine which words are BLMN only and which are shared BLMN/PREPOST
  #  length(levels(data$word))
   tab2 = as.data.frame(plyr::count(data,"word"))
    #plot(tab2$freq)
    #items occurring over 300 times are shared BLMN/PREPOST
    #and the items occurring under 200 times are BLMN only
    both <- droplevels(tab2[which(tab2$freq>300),])
    primary <- levels(both$word)
    only <- droplevels(tab2[which(tab2$freq<200),])
    generalization <- levels(only$word)

#Option to reduce to only primary words
#You can ignore it if you are including all words
    primarywords <- droplevels(data[which(data$word%in%primary),])
  #  head(primarywords)
  #  levels(primarywords$word)
    primarywords$word_type <- "primary"
    generalizationwords <- droplevels(data[which(data$word%in%generalization),])
  #  head(generalizationwords)
  #  levels(generalizationwords$word)
    generalizationwords$word_type <- "generalization"
    #Only uncomment this if you want to exclude generalization words
    #data <- primarywords

#Calculate average n of tokens per session
#str(data)
#levels(data$session)

tab = plyr::count(data, c("subject","session","prepost"))
#tab <- as.data.frame(tab)
BLMN <- tab[which(tab$prepost=="NA"),]
PREPOST <- tab[which(tab$prepost!="NA"),]
mBLMN <- mean(BLMN$freq)
sdBLMN <- sd(BLMN$freq)
mPREPOST <- mean(PREPOST$freq)
sdPREPOST <- sd(PREPOST$freq)

tx1 <- data
#str(tx1)
Children <- levels(tx1$subject)

#True baseline points
#For each child, calculate the percent of "yes" votes out of total votes in each session
#And average across sessions
bl1 <- droplevels(subset(tx1, sessiontype=="BL"))
nbl <- c()
bl1_sum <- c()
bl1_total <- c()
bl1_perc <- c()
bl1_m <- c()
bl1_sd <-c()
for (i in seq_along(Children)){
  child <- droplevels(subset(bl1, subject==Children[i],))
  nbl[i] <- length(levels(child$session))
  bl1_sum <- tapply(child$correct, child$session, sum, na.rm=TRUE)
  bl1_total <- tapply(child$total, child$session, sum, na.rm=TRUE)
  bl1_perc <- bl1_sum*100/bl1_total
  bl1_m[i] <- mean(bl1_perc)
  bl1_sd[i] <- sd(bl1_perc)
}

#Midpoints
#For each child, calculate the percent of "yes" votes out of total votes in each session
#And average across sessions
mp1 <- droplevels(subset(tx1, sessiontype=="MP"))
nmp <- c()
mp1_sum <- c()
mp1_total <- c()
mp1_perc <- c()
mp1_m <- c()
mp1_sd <-c()
for (i in seq_along(Children)){
  child <- droplevels(subset(mp1, subject==Children[i],))
  nmp[i] <- length(levels(child$session))
  mp1_sum <- tapply(child$correct, child$session, sum, na.rm=TRUE)
  mp1_total <- tapply(child$total, child$session, sum, na.rm=TRUE)
  mp1_perc <- mp1_sum*100/mp1_total
  mp1_m[i] <- mean(mp1_perc)
  mp1_sd[i] <- sd(mp1_perc)
}

#True maintenance points
mn1 <- subset(tx1, sessiontype=="MN")
nmn <- c()
mn1_sum <- c()
mn1_total <- c()
mn1_perc <- c()
mn1_m <- c()
mn1_sd <-c()
for (i in seq_along(Children)){
  child <- droplevels(subset(mn1, subject==Children[i],))
  nmn[i] <- length(levels(child$session))
  mn1_sum <- tapply(child$correct, child$session, sum, na.rm=TRUE)
  mn1_total <- tapply(child$total, child$session, sum, na.rm=TRUE)
  mn1_perc <- mn1_sum*100/mn1_total
  mn1_m[i] <- mean(mn1_perc)
  mn1_sd[i] <- sd(mn1_perc)
}

#Effect size 1: BL to MP
pooled1a <- sqrt(((nbl-1)*(bl1_sd^2) + (nmp-1)*(mp1_sd^2))/(nbl+nmp-2))

pooled1 <- ((nbl-1)*(bl1_sd^2)) %>%
  add((nmp-1)*(mp1_sd^2)) %>%
  divide_by(nbl+nmp-2) %>%
  raise_to_power(1/2)

#pooled1a==pooled1

ESPhase1 <- (mp1_m - bl1_m)/pooled1

#Effect size 2: MP to MN
pooled2a <- sqrt(((nmp-1)*(mp1_sd^2) + (nmn-1)*(mn1_sd^2))/(nmp+nmn-2))

pooled2 <- ((nmp-1)*(mp1_sd^2)) %>%
  add((nmn-1)*(mn1_sd^2)) %>%
  divide_by(nmp+nmn-2) %>%
  raise_to_power(1/2)

#pooled2a==pooled2

ESPhase2 <- (mn1_m - mp1_m)/pooled2

#Effect size 3: BL to MN
pooled3a <- sqrt(((nbl-1)*(bl1_sd^2) + (nmn-1)*(mn1_sd^2))/(nbl+nmn-2))

pooled3 <- ((nbl-1)*(bl1_sd^2)) %>%
  add((nmn-1)*(mn1_sd^2)) %>%
  divide_by(nbl+nmn-2) %>%
  raise_to_power(1/2)

#pooled3a==pooled3

ESall <- (mn1_m - bl1_m)/pooled2


bl1_m <- round(bl1_m, digits=2)
bl1_sd <- round(bl1_sd, digits=2)
mp1_m <- round(mp1_m, digits=2)
mp1_sd <- round(mp1_sd, digits=2)
mn1_m <- round(mn1_m, digits=2)
mn1_sd <- round(mn1_sd, digits=2)
pooled1 <- round(pooled1, digits=2)
ESPhase1 <- round(ESPhase1, digits=2)
pooled2 <- round(pooled2, digits=2)
ESPhase2 <- round(ESPhase2, digits=2)
pooled3 <- round(pooled3, digits=2)
ESall <- round(ESall, digits=2)

data1 <- data.frame(Children, bl1_m, bl1_sd,mp1_m, mp1_sd, mn1_m, mn1_sd, pooled1, ESPhase1, pooled2, ESPhase2, pooled3, ESall)
colnames(data1)[1] <- "subject" 
#str(data1)

#Add demographic info
demog  = read.csv("BFS2_demog.csv", header=T)
demog$subject <- as.factor(demog$subject)
data2 <- left_join(data1, demog, by="subject")
data2$subject <- as.factor(data2$subject)
#str(data2)

#Code by treatment type
TRAD1 <- droplevels(subset(data2, tx_order=="TRAD_BF"))
TRAD1$ES_TRAD <- TRAD1$ESPhase1
TRAD1$ES_BF <- TRAD1$ESPhase2

BF1 <- droplevels(subset(data2, tx_order=="BF_TRAD"))
BF1$ES_TRAD <- BF1$ESPhase2
BF1$ES_BF <- BF1$ESPhase1

data3 <- rbind(TRAD1, BF1) 
data3short <- data3[,1:13]
data3short$pooled1 <- NULL
data3short$pooled2 <- NULL
data3short$pooled3 <- NULL

#Diff in effect size between BF and TRAD conditions
#Putting BF first because hypothesized to have larger effect
data3$BF_advantage <- data3$ES_BF - data3$ES_TRAD

#Diff in effect size between first and second phases
#Putting Phase 2 first because hypothesized to show cumulative effect
data3$order_effect <- data3$ESPhase2 - data3$ESPhase1

######################################################
######################################################
#Write complete data table to file
#write.csv(data3, "cohort2_EF_data.csv")
#######################################################
######################################################

#Mean effect size across all participants for trad phase and BF phase
tradmeanES <- mean(data3$ES_TRAD)
BFmeanES <- mean(data3$ES_BF)

#Mean difference between BF and TRAD
#Small BF advantage, but lots of variability (large SD)
meanBFadvantage <- mean(data3$BF_advantage) 
sdBFadvantage <- sd(data3$BF_advantage) 

#Mean diff between phase 1 and phase 2 
#Generally a larger effect in phase 1 than phase 2, unexpectedly
#Note large SD
meanorder <- mean(data3$order_effect)
sdorder <- sd(data3$order_effect)

#Does the comparison of phase 1 vs phase 2 look different in BF-first vs TRAD-first?
TRAD1 <- droplevels(subset(data3, tx_order=="TRAD_BF"))
meanTRADorder <- mean(TRAD1$order_effect)
sdTRADorder <- sd(TRAD1$order_effect)

BF1 <- droplevels(subset(data3, tx_order=="BF_TRAD"))
meanBForder <- mean(BF1$order_effect)
sdBForder <- sd(BF1$order_effect)

#Both groups show larger generalization gains in phase 1 than phase 2
#But the difference is greater (advantage for phase 1 is greater) for BF-first group
#Note that this is not in keeping with the prediction that BF is better for acquisition 
#and TRAD is better for generalization

#Does overal effect size look different in BF-first vs TRAD-first?
meanTRADfirst <- mean(TRAD1$ESall)
sdTRADfirst <- sd(TRAD1$ESall)

meanBFfirst <- mean(BF1$ESall)
sdBFfirst <-sd(BF1$ESall)
#Large absolute difference, but extremely variable across participants; not significant
#t.test(TRAD1$ESall, BF1$ESall)

```

Effect sizes representing representing change in $\hat{p}_{correct}$ for the treated variant, vocalic /r/, are reported for all participants in Table 3. The first column shows participants' mean $\hat{p}_{correct}$ in the baseline period, averaged across all vocalic /r/ items from all sessions. The second column shows the equivalent mean across the three midpoint sessions, and the third shows the three maintenance sessions. The next three columns report three standardized effect sizes: ES~Phase1~ compares baseline versus midpoint scores, ES~Phase2~ compares midpoint versus maintenance scores, and ES~all~ compares baseline versus maintenance, reflecting overall gains across both phases of treatment. Participants are blocked by the order in which they received treatment (traditional-first or biofeedback-first). **The effect sizes in Table 3 show a wide range of variability in overall response to treatment across individuals. Averaging effect sizes across all participants yields a mean of `r #round(meanES, digits=2)`, suggesting that on average, participants' response to the combined biofeedback and traditional treatment package was positive and exceeded the minimum value considered clinically significant. Individual patterns of response will be examined in detail in the next section. **

```{r, echo=FALSE, fig.width=7, fig.height=2,message=FALSE, warning=FALSE}

library(knitr)
kable(data3short)
```

##Individual results: Visual inspection

Figures 2-4 represent each participant's pattern of change in accuracy ($\hat{p}_{correct}$) over time, which can be visually inspected to corroborate the effect sizes reported in Table 3. Discussion of differences in relative response to biofeedback versus traditional treatment will be deferred until the next section, which reports the results of individual randomization tests. In the single-subject plots in Figures 2-4, each child is represented by two boxes. The top box reflects performance on probe measures administered before and after each biofeedback treatment session and additionally reports probe scores from the pre-treatment baseline and post-treatment maintenance periods (shaded gray). The lower box reflects performance during traditional treatment sessions. Recall that sessions were randomly assigned to feature biofeedback or traditional treatment, but in a blocked fashion so that a participant experienced no more than two consecutive sessions of the same type. For each treatment session, a black circle represents performance on the pre-treatment probe measure, and a red star represents performance on the post-treatment probe. The y-axis represents $\hat{p}_{correct}$ aggregated across all vocalic /r/ items within a session; that is, the total number of "correct /r/" ratings as a percentage of the total number of ratings collected. Thus, the distance between the circle and the star within a session provide an index of the participant's progress (or lack thereof) during that treatment session. Finally, a dashed horizontal line tracks the participant's mean $\hat{p}_{correct}$ from the baseline interval, so that subsequent scores can be compared to the baseline mean. 

The mean number of probe words on which $\hat{p}_{correct}$ scores are based was `r mPREPOST` (SD = `r sdPREPOST`) for pre- and post-treatment probes and `r mBLMN` (SD = `r sdBLMN`) for baseline and maintenance probes. The number of ratings collected in connection with a given probe session (i.e., the denominator in $\hat{p}_{correct}$) was roughly nine times the number of items in that probe and often was larger.

For convenience, the single-subject graphs have been grouped into three sets of 2-5 participants who demonstrated similar effect sizes. Figure 2 depicts five participants who demonstrated a robust response to treatment (effect sizes of `r #data2[7,6]` and `r #data2[4,6]`, respectively). **Piper began with relatively high accuracy and rapidly attained ceiling-level accuracy, which she sustained through the remainder of treatment and the maintenance period. Garrett began with much lower accuracy and showed no meaningful progress on word probes for an extended period of time, but in the later part of the study he made slow but continuous gains. His accuracy in the maintenance period was substantially higher than its level at baseline, although his scores remained well below ceiling-level accuracy.** 


```{r, echo=FALSE, fig.width=7, fig.height=2,message=FALSE, warning=FALSE,strip.white=TRUE}
#################################################################
#FIGURE 2: POSITIVE EFFECT SIZES
#################################################################
#Read in data
data <- read.csv("clean_data.csv")
#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)
#Need to re-set ordered factors
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5","TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                                "MP1","MP2","MP3","TX11","TX12",
                                                "TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   

#Subset to appropriate group of children
data <- droplevels(filter(data, subject=="Adrian"|subject=="Emily"|subject=="Liam"|subject=="Emma"|subject=="Madison"))

#Specs for plotting
par(mfrow=c(3,1))
par(mar = c(.1, .1, .1, .1))
par(xpd=FALSE)

#Loop through participants
Children <- levels(data$subject)
for (i in seq_along(Children)){
  
  child <- droplevels(data[data$subject==Children[i],])
  numerical=c(1:length(levels(child$session)))
  minus <- length(numerical) - 2
  labels = levels(child$session)
  label = unique(child$subject)
  
  BL <- droplevels(subset(child, sessiontype=="BL"))
  nbl <- length(levels(BL$session))
  
  bl1_sum <- tapply(BL$correct, BL$session, sum, na.rm=TRUE)
  bl1_total <- tapply(BL$total, BL$session, sum, na.rm=TRUE)
  bl1_perc <- bl1_sum*100/bl1_total
  bl1_m <- mean(bl1_perc)
  
  #Plot Treated Targets
  ###NB name "BF" here is a holdover from cohort 1--
  ###both BF AND TRAD sessions are included in these plots
  #BF Pre
  BF <- subset(child, child$condition=="BF"|child$condition=="PROBE")
  BF_pre <- subset(BF, BF$prepost=="Pre"|BF$prepost=="PROBE")
  BF_pre_mean <- tapply(BF_pre$mean, BF_pre$session, mean)
  BF_pre_correct <- tapply(BF_pre$correct, BF_pre$session, sum)
  BF_pre_total <- tapply(BF_pre$total, BF_pre$session, sum)
  BF_pre_percent <- BF_pre_correct*100/BF_pre_total
  
  #BF Post
  BF_post <- subset(BF, BF$prepost=="Post")
  BF_post_mean <- tapply(BF_post$mean, BF_post$session, mean)
  BF_post_correct <- tapply(BF_post$correct, BF_post$session, sum)
  BF_post_total <- tapply(BF_post$total, BF_post$session, sum)
  BF_post_percent <- BF_post_correct*100/BF_post_total
  
  plot(numerical, BF_pre_percent, 
       main = label,
       xaxt="n", xlab = "Session", ylab = "Mean rating", ylim = c(0, 100))
  axis(1, at=numerical, labels=labels, cex.axis = 1.25)
  #Plot baseline mean
  yline(bl1_m, lty=2)
  
  points(numerical+.2, BF_post_percent,  pch = 8, col = "red", lty=2) 
  
  #Set points for shading BL, MP, and MN regions
  endBL <- nbl + .5
  beginMP <- endBL + 10
  endMP <- beginMP + 3
  beginMN <- endMP + 10
  endMN <- beginMN + 3
  color <- rgb(190, 190, 190, alpha=80, maxColorValue=255)
  rect(xleft=0.0-1, xright=endBL, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMP, xright=endMP, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMN, xright=endMN, ybottom=-4, ytop=106, density=100, 
       col=color)
  
  #Plot TRAD
  #TRAD Pre
  TRAD_pre <- subset(child, child$condition=="Trad"&child$prepost=="Pre")
  TRAD_pre_mean <- tapply(TRAD_pre$mean, TRAD_pre$session, mean)
  TRAD_pre_correct <- tapply(TRAD_pre$correct, TRAD_pre$session, sum)
  TRAD_pre_total <- tapply(TRAD_pre$total, TRAD_pre$session, sum)
  TRAD_pre_percent <- TRAD_pre_correct*100/TRAD_pre_total
  #TRAD Post
  TRAD_post <- subset(child, child$condition=="Trad"&child$prepost=="Post")
  TRAD_post_mean <- tapply(TRAD_post$mean, TRAD_post$session, mean)
  TRAD_post_correct <- tapply(TRAD_post$correct, TRAD_post$session, sum)
  TRAD_post_total <- tapply(TRAD_post$total, TRAD_post$session, sum)
  TRAD_post_percent <- TRAD_post_correct*100/TRAD_post_total
  
  #Plot points
  points(numerical, TRAD_pre_percent,  pch = 12, col = "blue", lty=2) 
  points(numerical+.2, TRAD_post_percent,  pch = 6, col = "green", lty=2) 

  #*Place a legend based on mean rating of MN sessions*
  ifelse(mean(rev(BF_pre_percent)[1:3]) <= 50, 
         legend("topright",cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,1,12,6), col=c("black","red", "blue","green"), bg = "white"), 
         legend("bottomright" ,cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,1,12,6), col=c("black","red", "blue","green"), bg = "white"))
  
}

```

**Figure 2. Longitudinal plots of $\hat{p}_{correct}$ for participants with large positive effect sizes. Dashed line represents mean across baseline sessions. BL = Baseline, Tx = Treatment, MN = Maintenance.**


Figure 3 shows two participants, **Ian and Clara, whose effect sizes were smaller but still exceeded the minimum to be considered clinically relevant (`r #data2[5,6]` and `r #data2[1,6]`, respectively). Visual inspection reveals a pattern of change over time that is also consistent  with a meaningful response to treatment. Ian, who had the longest duration of previous unsuccessful treatment out of all participants in the study, exhibited virtually no change in accuracy in the first 15 sessions of treatment. In the final five sessions, though, his accuracy in pre-treatment probes reliably exceeded baseline levels, with substantial additional gains in each post-treatment probe. Unfortunately, these gains were tenuous, and scores drifted back down to baseline levels over the course of the maintenance period. Clara reliably exceeded baseline-level performance in both pre- and post-treatment probes throughout the course of treatment. Like Ian, though, her gains appeared substantially weaker in the post-treatment maintenance interval. This may relect the fact that the full probe measure administered in baseline and maintenance sessions contained additional items that were less familiar than the fixed 25-word subset that was administered at the start and end of each treatment session.**

```{r, echo=FALSE, fig.width=7, fig.height=2,message=FALSE, warning=FALSE}
#################################################################
#FIGURE 3: SMALL POSITIVE EFFECT SIZES
#################################################################
#Read in data
data <- read.csv("clean_data.csv")
#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)
#Need to re-set ordered factors
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5","TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                                "MP1","MP2","MP3","TX11","TX12",
                                                "TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   

#Subset to appropriate group of children
data <- droplevels(filter(data, subject=="Jack"|subject=="Gabriel"))

#Specs for plotting
par(mfrow=c(3,1))
par(mar = c(.1, .1, .1, .1))
par(xpd=FALSE)

#Loop through participants
Children <- levels(data$subject)
for (i in seq_along(Children)){
  
  child <- droplevels(data[data$subject==Children[i],])
  numerical=c(1:length(levels(child$session)))
  minus <- length(numerical) - 2
  labels = levels(child$session)
  label = unique(child$subject)
  
  BL <- droplevels(subset(child, sessiontype=="BL"))
  nbl <- length(levels(BL$session))
  
  bl1_sum <- tapply(BL$correct, BL$session, sum, na.rm=TRUE)
  bl1_total <- tapply(BL$total, BL$session, sum, na.rm=TRUE)
  bl1_perc <- bl1_sum*100/bl1_total
  bl1_m <- mean(bl1_perc)
  
  #Plot Treated Targets
  ###NB name "BF" here is a holdover from cohort 1--
  ###both BF AND TRAD sessions are included in these plots
  #BF Pre
  BF <- subset(child, child$condition=="BF"|child$condition=="PROBE")
  BF_pre <- subset(BF, BF$prepost=="Pre"|BF$prepost=="PROBE")
  BF_pre_mean <- tapply(BF_pre$mean, BF_pre$session, mean)
  BF_pre_correct <- tapply(BF_pre$correct, BF_pre$session, sum)
  BF_pre_total <- tapply(BF_pre$total, BF_pre$session, sum)
  BF_pre_percent <- BF_pre_correct*100/BF_pre_total
  
  #BF Post
  BF_post <- subset(BF, BF$prepost=="Post")
  BF_post_mean <- tapply(BF_post$mean, BF_post$session, mean)
  BF_post_correct <- tapply(BF_post$correct, BF_post$session, sum)
  BF_post_total <- tapply(BF_post$total, BF_post$session, sum)
  BF_post_percent <- BF_post_correct*100/BF_post_total
  
  plot(numerical, BF_pre_percent, 
       main = label,
       xaxt="n", xlab = "Session", ylab = "Mean rating", ylim = c(0, 100))
  axis(1, at=numerical, labels=labels, cex.axis = 1.25)
  #Plot baseline mean
  yline(bl1_m, lty=2)
  
  points(numerical+.2, BF_post_percent,  pch = 8, col = "red", lty=2) 
  
  #Set points for shading BL, MP, and MN regions
  endBL <- nbl + .5
  beginMP <- endBL + 10
  endMP <- beginMP + 3
  beginMN <- endMP + 10
  endMN <- beginMN + 3
  color <- rgb(190, 190, 190, alpha=80, maxColorValue=255)
  rect(xleft=0.0-1, xright=endBL, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMP, xright=endMP, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMN, xright=endMN, ybottom=-4, ytop=106, density=100, 
       col=color)
  
  #Plot TRAD
  #TRAD Pre
  TRAD_pre <- subset(child, child$condition=="Trad"&child$prepost=="Pre")
  TRAD_pre_mean <- tapply(TRAD_pre$mean, TRAD_pre$session, mean)
  TRAD_pre_correct <- tapply(TRAD_pre$correct, TRAD_pre$session, sum)
  TRAD_pre_total <- tapply(TRAD_pre$total, TRAD_pre$session, sum)
  TRAD_pre_percent <- TRAD_pre_correct*100/TRAD_pre_total
  #TRAD Post
  TRAD_post <- subset(child, child$condition=="Trad"&child$prepost=="Post")
  TRAD_post_mean <- tapply(TRAD_post$mean, TRAD_post$session, mean)
  TRAD_post_correct <- tapply(TRAD_post$correct, TRAD_post$session, sum)
  TRAD_post_total <- tapply(TRAD_post$total, TRAD_post$session, sum)
  TRAD_post_percent <- TRAD_post_correct*100/TRAD_post_total
  
  #Plot points
  points(numerical, TRAD_pre_percent,  pch = 12, col = "blue", lty=2) 
  points(numerical+.2, TRAD_post_percent,  pch = 6, col = "green", lty=2) 

  #*Place a legend based on mean rating of MN sessions*
  ifelse(mean(rev(BF_pre_percent)[1:3]) <= 50, 
         legend("topright",cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,1,12,6), col=c("black","red", "blue","green"), bg = "white"), 
         legend("bottomright" ,cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,1,12,6), col=c("black","red", "blue","green"), bg = "white"))
  
}

```

**Figure 3. Longitudinal plots of $\hat{p}_{correct}$ for participants with small positive effect sizes. Dashed line represents mean across baseline sessions. BL = Baseline, Tx = Treatment, MN = Maintenance.**

Finally, Figure 4 shows three participants who demonstrated a null or negative effect size over the course of the study. **One participant, Felix, showed virtually no variation in accuracy over the course of the study, yielding a final effect size of `r #data2[3,6]`. The second participant, Lucas, showed a similar effect size (`r #data2[6,6]`) but exhibited much more variability in his performance within treatment sessions, including scores substantially higher and lower than the baseline mean. This case will be examined in greater detail below in connection with the discussion of relative response to biofeedback versus traditional treatment. The last participant, Evan, showed a small but continuous decline in accuracy over the course of treatment. The overall magnitude of this decrease was less than 10 percentage points, but the standardized effect size was quite large, `r #data2[2,6]`. This is in part a reflection of unusually low variance in Evan's ratings: his pooled standard deviation in $\hat{p}_{correct}$ was `r #data2[2,5]`, whereas the standard deviation averaged across the group was `r #meanpooled` (SD = `r #sdpooled`).** 


```{r, echo=FALSE, fig.width=7, fig.height=2,message=FALSE, warning=FALSE}
#################################################################
#FIGURE 3: NULL/NEGATIVE EFFECT SIZES
#################################################################
#Read in data
data <- read.csv("clean_data.csv")
#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)
#Need to re-set ordered factors
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5","TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                                "MP1","MP2","MP3","TX11","TX12",
                                                "TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   

#Subset to appropriate group of children
data <- droplevels(filter(data, subject=="Brooklyn"|subject=="Hailey"|subject=="Connor"|subject=="Hannah"))

#Specs for plotting
par(mfrow=c(3,1))
par(mar = c(.1, .1, .1, .1))
par(xpd=FALSE)

#Loop through participants
Children <- levels(data$subject)
for (i in seq_along(Children)){
  
  child <- droplevels(data[data$subject==Children[i],])
  numerical=c(1:length(levels(child$session)))
  minus <- length(numerical) - 2
  labels = levels(child$session)
  label = unique(child$subject)
  
  BL <- droplevels(subset(child, sessiontype=="BL"))
  nbl <- length(levels(BL$session))
  
  bl1_sum <- tapply(BL$correct, BL$session, sum, na.rm=TRUE)
  bl1_total <- tapply(BL$total, BL$session, sum, na.rm=TRUE)
  bl1_perc <- bl1_sum*100/bl1_total
  bl1_m <- mean(bl1_perc)
  
  #Plot Treated Targets
  ###NB name "BF" here is a holdover from cohort 1--
  ###both BF AND TRAD sessions are included in these plots
  #BF Pre
  BF <- subset(child, child$condition=="BF"|child$condition=="PROBE")
  BF_pre <- subset(BF, BF$prepost=="Pre"|BF$prepost=="PROBE")
  BF_pre_mean <- tapply(BF_pre$mean, BF_pre$session, mean)
  BF_pre_correct <- tapply(BF_pre$correct, BF_pre$session, sum)
  BF_pre_total <- tapply(BF_pre$total, BF_pre$session, sum)
  BF_pre_percent <- BF_pre_correct*100/BF_pre_total
  
  #BF Post
  BF_post <- subset(BF, BF$prepost=="Post")
  BF_post_mean <- tapply(BF_post$mean, BF_post$session, mean)
  BF_post_correct <- tapply(BF_post$correct, BF_post$session, sum)
  BF_post_total <- tapply(BF_post$total, BF_post$session, sum)
  BF_post_percent <- BF_post_correct*100/BF_post_total
  
  plot(numerical, BF_pre_percent, 
       main = label,
       xaxt="n", xlab = "Session", ylab = "Mean rating", ylim = c(0, 100))
  axis(1, at=numerical, labels=labels, cex.axis = 1.25)
  #Plot baseline mean
  yline(bl1_m, lty=2)
  
  points(numerical+.2, BF_post_percent,  pch = 8, col = "red", lty=2) 
  
  #Set points for shading BL, MP, and MN regions
  endBL <- nbl + .5
  beginMP <- endBL + 10
  endMP <- beginMP + 3
  beginMN <- endMP + 10
  endMN <- beginMN + 3
  color <- rgb(190, 190, 190, alpha=80, maxColorValue=255)
  rect(xleft=0.0-1, xright=endBL, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMP, xright=endMP, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMN, xright=endMN, ybottom=-4, ytop=106, density=100, 
       col=color)
  
  #Plot TRAD
  #TRAD Pre
  TRAD_pre <- subset(child, child$condition=="Trad"&child$prepost=="Pre")
  TRAD_pre_mean <- tapply(TRAD_pre$mean, TRAD_pre$session, mean)
  TRAD_pre_correct <- tapply(TRAD_pre$correct, TRAD_pre$session, sum)
  TRAD_pre_total <- tapply(TRAD_pre$total, TRAD_pre$session, sum)
  TRAD_pre_percent <- TRAD_pre_correct*100/TRAD_pre_total
  #TRAD Post
  TRAD_post <- subset(child, child$condition=="Trad"&child$prepost=="Post")
  TRAD_post_mean <- tapply(TRAD_post$mean, TRAD_post$session, mean)
  TRAD_post_correct <- tapply(TRAD_post$correct, TRAD_post$session, sum)
  TRAD_post_total <- tapply(TRAD_post$total, TRAD_post$session, sum)
  TRAD_post_percent <- TRAD_post_correct*100/TRAD_post_total
  
  #Plot points
  points(numerical, TRAD_pre_percent,  pch = 12, col = "blue", lty=2) 
  points(numerical+.2, TRAD_post_percent,  pch = 6, col = "green", lty=2) 

  #*Place a legend based on mean rating of MN sessions*
  ifelse(mean(rev(BF_pre_percent)[1:3]) <= 50, 
         legend("topright",cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,1,12,6), col=c("black","red", "blue","green"), bg = "white"), 
         legend("bottomright" ,cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,1,12,6), col=c("black","red", "blue","green"), bg = "white"))
  
}

```

**Figure 4. Longitudinal plots of $\hat{p}_{correct}$ for participants with null or negative effect size. Dashed line represents mean across baseline sessions. BL = Baseline, Tx = Treatment, MN = Maintenance.**

```{r, echo=FALSE, fig.width=7, fig.height=2,message=FALSE, warning=FALSE}
   
```

##Comparing biofeedback versus traditional: Generalization probes

Considering generalization gains in each phase (BL-MP and MP-MN):
Which participants showed an advantage for one phase over the other?
Was there an effect of BF vs traditional (independent of order)?
Was there an order effect (independent of treatment type)?

##Comparing biofeedback versus traditional: Short-term gains

Considering within-treatment gains (Post-Pre, averaged across sessions in a phase):
Which participants showed an advantage for one phase over the other?
Was there an effect of BF vs traditional (independent of order)?
Was there an order effect (independent of treatment type)?

```{r, echo=FALSE, fig.width=7, fig.height=2.5,message=FALSE, warning=FALSE}
#############################################################
#WITHIN-TREATMNET CHANGE SCORES
#############################################################
data <- read.csv("clean_data.csv")
#dim(data)
#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)


#This code creates an option to plot only the primary words and exclude generalization words
#You can ignore it if you are including all words

#For within-session, consider only treatment session data
TX <- droplevels(subset(data, sessiontype=="TX"))
ntx <- length(levels(TX$session))

#Need to re-set ordered factors
TX$session = ordered(TX$session, levels = c("TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                            "TX11","TX12","TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20"))   
TX$prepost = ordered(TX$prepost, levels= c("Pre","Post"))



#Summarize by subject, session, prepost
#Include condition (BF vs TRAD) and tx_order as grouping factors
#because you want to preserve this info
TX <- TX %>%
  dplyr::group_by(subject, session, prepost, condition, tx_order) %>%
    dplyr::summarise(correct = sum(correct), total = sum(total))
TX$percent <- 100*TX$correct/TX$total
TX <- as.data.frame(TX)

#Calculate within-session differences by subject
#First use spread() to put pre and post side by side
#Get rid of other numeric columns or they will create NA values
TX$correct <-NULL
TX$total <- NULL
TX <- spread(TX, prepost, percent)

#Create a difference column
#Subtract pre from post on assumption that post will be higher
TX$diff <- TX$Post - TX$Pre
#head(TX)

#Visualize the values
#TX$tx_order[1]
#Loop through participants
Children <- levels(TX$subject)
numerical <- 1:length(levels(TX$session))
for (i in seq_along(Children)){
  child <- droplevels(TX[TX$subject==Children[i],])
  condition <- as.character(child$tx_order[1])
  plot(child$session, child$diff, type="o",
       xaxt="n", xlab = "Session", ylab = "Mean rating", main = c(Children[i],condition), ylim = c(-50, 50))
  axis(1, at=numerical,  cex.axis = 1.25)
  xline(10.5, lty=2)
  yline(0, lty=2)
}

#Calculate means for each phase
#Temp option to strike Hannah data due to missing session
TX <- droplevels(TX[TX$subject!="Hannah",])
#str(TX)

#Code by treatment phase (chronological order; 1 or 2)
TX$phase <- 0
TX[which(TX$session<="TX10"),]$phase <- "1"
TX[which(TX$session>"TX10"),]$phase <- "2"
#TX$unique <- paste0(TX$subject,"_",TX$phase)


#Summarize by phase
TX <- TX %>%
  dplyr::group_by(subject, phase, condition) %>%
    dplyr::summarise(mean=mean(diff))

TX <- as.data.frame(TX)

#Compare mean within-session change for first vs second phase (chronologically)
phase1 <- droplevels(TX[TX$phase==1,])
phase2 <- droplevels(TX[TX$phase==2,])
#mean(phase1$mean)
#sd(phase1$mean)
#mean(phase2$mean)
#sd(phase2$mean)
#t.test(phase1$mean, phase2$mean)
#NS

#Compare mean within-session change for Trad phase vs BF phase 
Trad <- droplevels(TX[TX$condition=="Trad",])
BF <- droplevels(TX[TX$condition=="BF",])
#mean(Trad$mean)
#sd(Trad$mean)
#mean(BF$mean)
#sd(BF$mean)
#Mean is larger for BF than Trad, but highly variable; nonsignificant
#t.test(BF$mean, Trad$mean)
#NS

#I don't know why this boxplot isn't working
#qplot(TX$mean, fill = TX$condition, geom="boxplot")

#Compare Trad vs BF means in a within-subject fashion
TX$phase <- NULL
TX <- TX %>% 
  spread(condition, mean)
#t.test(TX$BF, TX$Trad, paired=TRUE)
#Still definitely NS

```

##Overall order effect
Compare BF_TRAD versus TRAD_BF groups.
Mixed model?

